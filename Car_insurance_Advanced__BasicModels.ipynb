{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u31vSJ1x3WO",
        "outputId": "981e0f83-d850-4177-e859-ecf0c5cd5511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YpmxB1lbyRg4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XuLOG6vEyPpK"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/ST4052/project1_Advanced/pls_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS7z5w4lyuZn",
        "outputId": "853125d6-3de7-41b1-982b-422bc73159af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58592, 46)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3uoFHrpDyjKH"
      },
      "outputs": [],
      "source": [
        "#feature set\n",
        "X = data.drop('is_claim',axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRsFEZvIyybu",
        "outputId": "565248e5-1914-4c5a-a05b-1cda49e16acf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58592, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cE0gM3cyy1VX"
      },
      "outputs": [],
      "source": [
        "#response\n",
        "y = data['is_claim']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNmgpXMxy-0I",
        "outputId": "886bd4f4-c7d5-46d3-baf1-04c4b6d1568f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58592,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-RjAsaEQzGxY"
      },
      "outputs": [],
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting Models"
      ],
      "metadata": {
        "id": "iQiKowqREMOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Origrinal data set"
      ],
      "metadata": {
        "id": "bG9H4qGxEf8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Fit each classifier and compute evaluation metrics\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_train_pred = clf.predict(X_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    train_precision = precision_score(y_train, y_train_pred)\n",
        "    test_precision = precision_score(y_test, y_test_pred)\n",
        "\n",
        "    train_recall = recall_score(y_train, y_train_pred)\n",
        "    test_recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f1 = f1_score(y_train, y_train_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f2 = fbeta_score(y_train, y_train_pred, beta=2)\n",
        "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "    results[clf_name] = {\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Test Precision': test_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Test Recall': test_recall,\n",
        "        'Train F1-Score': train_f1,\n",
        "        'Test F1-Score': test_f1,\n",
        "        'Train F2-Score': train_f2,\n",
        "        'Test F2-Score': test_f2\n",
        "    }\n",
        "\n",
        "# Create a table for evaluation metrics\n",
        "metrics_table = pd.DataFrame(results).T\n",
        "\n",
        "print(\"Evaluation Metrics (Training and Test Data):\")\n",
        "print(metrics_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab6c142-21b5-4483-a615-7bade7cca985",
        "id": "bsOBLQojKSSH"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics (Training and Test Data):\n",
            "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
            "Logistic Regression        0.936168       0.935489         0.000000   \n",
            "Naive Bayes                0.896358       0.899650         0.073193   \n",
            "K-Nearest Neighbors        0.936979       0.932503         0.620253   \n",
            "Random Forest              0.999893       0.931137         1.000000   \n",
            "XGBoost                    0.937448       0.935319         1.000000   \n",
            "\n",
            "                     Test Precision  Train Recall  Test Recall  \\\n",
            "Logistic Regression        0.000000      0.000000     0.000000   \n",
            "Naive Bayes                0.073171      0.053476     0.047619   \n",
            "K-Nearest Neighbors        0.111111      0.032754     0.006614   \n",
            "Random Forest              0.067797      0.998329     0.005291   \n",
            "XGBoost                    0.000000      0.020053     0.000000   \n",
            "\n",
            "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
            "Logistic Regression        0.000000       0.000000        0.000000   \n",
            "Naive Bayes                0.061800       0.057692        0.056521   \n",
            "K-Nearest Neighbors        0.062222       0.012484        0.040409   \n",
            "Random Forest              0.999164       0.009816        0.998663   \n",
            "XGBoost                    0.039318       0.000000        0.024942   \n",
            "\n",
            "                     Test F2-Score  \n",
            "Logistic Regression       0.000000  \n",
            "Naive Bayes               0.051195  \n",
            "K-Nearest Neighbors       0.008146  \n",
            "Random Forest             0.006487  \n",
            "XGBoost                   0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Balancing with SMOTE"
      ],
      "metadata": {
        "id": "LcUDFVr0F5Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to balance the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Fit each classifier and compute evaluation metrics\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train_resampled, y_train_resampled)\n",
        "    y_train_pred = clf.predict(X_train_resampled)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
        "    test_precision = precision_score(y_test, y_test_pred)\n",
        "\n",
        "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
        "    test_recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "    results[clf_name] = {\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Test Precision': test_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Test Recall': test_recall,\n",
        "        'Train F1-Score': train_f1,\n",
        "        'Test F1-Score': test_f1,\n",
        "        'Train F2-Score': train_f2,\n",
        "        'Test F2-Score': test_f2\n",
        "    }\n",
        "\n",
        "# Create a table for evaluation metrics\n",
        "metrics_table = pd.DataFrame(results).T\n",
        "\n",
        "print(\"Evaluation Metrics (Training and Test Data):\")\n",
        "print(metrics_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_R8E3EYGADJ",
        "outputId": "b34c3241-1820-4ce3-ed8c-0c96bc442b49"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics (Training and Test Data):\n",
            "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
            "Logistic Regression        0.585800       0.572148         0.582392   \n",
            "Naive Bayes                0.536269       0.401485         0.527603   \n",
            "K-Nearest Neighbors        0.894294       0.709788         0.838445   \n",
            "Random Forest              0.999989       0.898114         0.999977   \n",
            "XGBoost                    0.962706       0.932844         0.998160   \n",
            "\n",
            "                     Test Precision  Train Recall  Test Recall  \\\n",
            "Logistic Regression        0.082057      0.606481     0.552910   \n",
            "Naive Bayes                0.069601      0.693239     0.669312   \n",
            "K-Nearest Neighbors        0.080824      0.976801     0.337302   \n",
            "Random Forest              0.103261      1.000000     0.075397   \n",
            "XGBoost                    0.121951      0.927121     0.006614   \n",
            "\n",
            "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
            "Logistic Regression        0.594193       0.142906        0.601505   \n",
            "Naive Bayes                0.599185       0.126090        0.652283   \n",
            "K-Nearest Neighbors        0.902350       0.130401        0.945594   \n",
            "Random Forest              0.999989       0.087156        0.999995   \n",
            "XGBoost                    0.961330       0.012547        0.940508   \n",
            "\n",
            "                     Test F2-Score  \n",
            "Logistic Regression       0.257453  \n",
            "Naive Bayes               0.245774  \n",
            "K-Nearest Neighbors       0.206344  \n",
            "Random Forest             0.079698  \n",
            "XGBoost                   0.008157  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Balancing with OverSampling"
      ],
      "metadata": {
        "id": "JdiH0-1EL5AD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Apply Random Oversampling to balance the training set\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Fit each classifier and compute evaluation metrics\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train_resampled, y_train_resampled)\n",
        "    y_train_pred = clf.predict(X_train_resampled)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
        "    test_precision = precision_score(y_test, y_test_pred)\n",
        "\n",
        "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
        "    test_recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "    results[clf_name] = {\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Test Precision': test_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Test Recall': test_recall,\n",
        "        'Train F1-Score': train_f1,\n",
        "        'Test F1-Score': test_f1,\n",
        "        'Train F2-Score': train_f2,\n",
        "        'Test F2-Score': test_f2\n",
        "    }\n",
        "\n",
        "# Create a table for evaluation metrics\n",
        "metrics_table = pd.DataFrame(results).T\n",
        "\n",
        "print(\"Evaluation Metrics (Training and Test Data):\")\n",
        "print(metrics_table)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNo4o0rsIAcg",
        "outputId": "eb2a555c-1abc-4d01-d9c6-edfcb7615137"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics (Training and Test Data):\n",
            "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
            "Logistic Regression        0.579100       0.566772         0.575968   \n",
            "Naive Bayes                0.525945       0.364622         0.518909   \n",
            "K-Nearest Neighbors        0.941056       0.785391         0.894545   \n",
            "Random Forest              0.999989       0.920300         0.999977   \n",
            "XGBoost                    0.810613       0.696134         0.770823   \n",
            "\n",
            "                     Test Precision  Train Recall  Test Recall  \\\n",
            "Logistic Regression        0.082512      0.599713     0.564815   \n",
            "Naive Bayes                0.068943      0.711994     0.707672   \n",
            "K-Nearest Neighbors        0.080591      1.000000     0.223545   \n",
            "Random Forest              0.087963      1.000000     0.025132   \n",
            "XGBoost                    0.100086      0.884073     0.464286   \n",
            "\n",
            "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
            "Logistic Regression        0.587601       0.143989        0.594809   \n",
            "Naive Bayes                0.600307       0.125646        0.662678   \n",
            "K-Nearest Neighbors        0.944337       0.118472        0.976966   \n",
            "Random Forest              0.999989       0.039095        0.999995   \n",
            "XGBoost                    0.823573       0.164673        0.858837   \n",
            "\n",
            "                     Test F2-Score  \n",
            "Logistic Regression       0.260398  \n",
            "Naive Bayes               0.248053  \n",
            "K-Nearest Neighbors       0.165007  \n",
            "Random Forest             0.029321  \n",
            "XGBoost                   0.268718  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.Balancing With UnderSampling"
      ],
      "metadata": {
        "id": "seUWp7SAMIPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Apply Random Undersampling to the training set\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Fit each classifier and compute evaluation metrics\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_train_resampled, y_train_resampled)\n",
        "    y_train_pred = clf.predict(X_train_resampled)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
        "    test_precision = precision_score(y_test, y_test_pred)\n",
        "\n",
        "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
        "    test_recall = recall_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
        "    test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "    results[clf_name] = {\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Test Precision': test_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Test Recall': test_recall,\n",
        "        'Train F1-Score': train_f1,\n",
        "        'Test F1-Score': test_f1,\n",
        "        'Train F2-Score': train_f2,\n",
        "        'Test F2-Score': test_f2\n",
        "    }\n",
        "\n",
        "# Create a table for evaluation metrics\n",
        "metrics_table = pd.DataFrame(results).T\n",
        "\n",
        "print(\"Evaluation Metrics (Training and Test Data with Random Undersampling):\")\n",
        "print(metrics_table)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWD3o6rpMN0C",
        "outputId": "c3fec947-2fc5-44f4-b7b0-ec4a8b012824"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics (Training and Test Data with Random Undersampling):\n",
            "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
            "Logistic Regression        0.576872       0.556447         0.573576   \n",
            "Naive Bayes                0.535261       0.420599         0.528599   \n",
            "K-Nearest Neighbors        0.709726       0.531018         0.704198   \n",
            "Random Forest              1.000000       0.578462         1.000000   \n",
            "XGBoost                    0.858122       0.556873         0.842004   \n",
            "\n",
            "                     Test Precision  Train Recall  Test Recall  \\\n",
            "Logistic Regression        0.081101      0.599265     0.568783   \n",
            "Naive Bayes                0.070839      0.651738     0.658730   \n",
            "K-Nearest Neighbors        0.074201      0.723262     0.546296   \n",
            "Random Forest              0.086070      1.000000     0.575397   \n",
            "XGBoost                    0.083849      0.881684     0.591270   \n",
            "\n",
            "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
            "Logistic Regression        0.586139       0.141961        0.593945   \n",
            "Naive Bayes                0.583745       0.127922        0.622725   \n",
            "K-Nearest Neighbors        0.713603       0.130655        0.719367   \n",
            "Random Forest              1.000000       0.149742        1.000000   \n",
            "XGBoost                    0.861388       0.146870        0.873452   \n",
            "\n",
            "                     Test F2-Score  \n",
            "Logistic Regression       0.258227  \n",
            "Naive Bayes               0.247663  \n",
            "K-Nearest Neighbors       0.240396  \n",
            "Random Forest             0.269250  \n",
            "XGBoost                   0.267504  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Now we selected Random forest with SMOTE balancing has some higher performance"
      ],
      "metadata": {
        "id": "bqYf5I9vNoQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we do some cost sensitive learning to improve F1 score"
      ],
      "metadata": {
        "id": "gFhxu0WcO8ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to balance the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create a Random Forest classifier with class weights\n",
        "class_weights = {0: 1, 1: 1000}  # You can adjust the weight for each class as needed\n",
        "rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weights)\n",
        "\n",
        "# Fit the model to your resampled training data\n",
        "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on both train and test data\n",
        "y_train_pred = rf_classifier.predict(X_train_resampled)\n",
        "y_test_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, F1, and F2 scores for both train and test sets\n",
        "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
        "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
        "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "# Create a table for the results\n",
        "results_table = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'F1-Score', 'F2-Score'],\n",
        "    'Train': [accuracy_train, f1_train, f2_train],\n",
        "    'Test': [accuracy_test, f1_test, f2_test]\n",
        "})\n",
        "\n",
        "print(\"Results:\")\n",
        "print(results_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG3NIWarO7TF",
        "outputId": "66b8c179-c184-43b6-92da-db99dda86d5a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "     Metric  Train      Test\n",
            "0  Accuracy    1.0  0.909293\n",
            "1  F1-Score    1.0  0.068361\n",
            "2  F2-Score    1.0  0.057202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit SVM and for SMOTE Dataset and Evaluate"
      ],
      "metadata": {
        "id": "LQN_am4DOfJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Apply SMOTE to balance the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm_classifier = SVC()\n",
        "\n",
        "# Fit the SVM model to the resampled training data\n",
        "svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions on both train and test data\n",
        "y_train_pred = svm_classifier.predict(X_train_resampled)\n",
        "y_test_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
        "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
        "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
        "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
        "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
        "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "\n",
        "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "precision_test = precision_score(y_test, y_test_pred)\n",
        "recall_test = recall_score(y_test, y_test_pred)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "# Create a table for the results\n",
        "results_table = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
        "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
        "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
        "})\n",
        "\n",
        "print(\"Results:\")\n",
        "print(results_table)\n"
      ],
      "metadata": {
        "id": "PhBsINklPurg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit RF model with hyper parameter tuning"
      ],
      "metadata": {
        "id": "rAMhpdcbQ_dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to balance the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define hyperparameters for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "    #'class_weight': [{0: 1, 1: 10}, {0: 1, 1: 15}]  # You can adjust class weights as needed\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best estimator from the hyperparameter tuning\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on both train and test data\n",
        "y_train_pred = best_rf_classifier.predict(X_train_resampled)\n",
        "y_test_pred = best_rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
        "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
        "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
        "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
        "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
        "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
        "\n",
        "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "precision_test = precision_score(y_test, y_test_pred)\n",
        "recall_test = recall_score(y_test, y_test_pred)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
        "\n",
        "# Create a table for the results\n",
        "results_table = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
        "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
        "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
        "})\n",
        "\n",
        "print(\"Results:\")\n",
        "print(results_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "paZjeEpcRGat",
        "outputId": "be3e10cd-996e-4653-ffdd-6c7297911731"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-91766226a2bf>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Perform hyperparameter tuning using GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Get the best estimator from the hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hNsH18jAXlBt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}