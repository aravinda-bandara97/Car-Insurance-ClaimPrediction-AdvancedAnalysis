{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Insurance Claim prediction - Advanced Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out Basic model without Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YpmxB1lbyRg4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XuLOG6vEyPpK"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('pls_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wS7z5w4lyuZn",
    "outputId": "853125d6-3de7-41b1-982b-422bc73159af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58592, 46)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3uoFHrpDyjKH"
   },
   "outputs": [],
   "source": [
    "#feature set\n",
    "X = data.drop('is_claim',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRsFEZvIyybu",
    "outputId": "565248e5-1914-4c5a-a05b-1cda49e16acf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58592, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cE0gM3cyy1VX"
   },
   "outputs": [],
   "source": [
    "#response\n",
    "y = data['is_claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNmgpXMxy-0I",
    "outputId": "886bd4f4-c7d5-46d3-baf1-04c4b6d1568f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58592,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-RjAsaEQzGxY"
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG9H4qGxEf8x"
   },
   "source": [
    "### 1. Imbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsOBLQojKSSH",
    "outputId": "1ab6c142-21b5-4483-a615-7bade7cca985",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (Training and Test Data):\n",
      "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
      "Logistic Regression        0.936168       0.935489         0.000000   \n",
      "Naive Bayes                0.896358       0.899650         0.073193   \n",
      "K-Nearest Neighbors        0.936979       0.932503         0.620253   \n",
      "Random Forest              0.999893       0.931137         1.000000   \n",
      "XGBoost                    0.937448       0.935319         1.000000   \n",
      "\n",
      "                     Test Precision  Train Recall  Test Recall  \\\n",
      "Logistic Regression        0.000000      0.000000     0.000000   \n",
      "Naive Bayes                0.073171      0.053476     0.047619   \n",
      "K-Nearest Neighbors        0.111111      0.032754     0.006614   \n",
      "Random Forest              0.067797      0.998329     0.005291   \n",
      "XGBoost                    0.000000      0.020053     0.000000   \n",
      "\n",
      "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
      "Logistic Regression        0.000000       0.000000        0.000000   \n",
      "Naive Bayes                0.061800       0.057692        0.056521   \n",
      "K-Nearest Neighbors        0.062222       0.012484        0.040409   \n",
      "Random Forest              0.999164       0.009816        0.998663   \n",
      "XGBoost                    0.039318       0.000000        0.024942   \n",
      "\n",
      "                     Test F2-Score  \n",
      "Logistic Regression       0.000000  \n",
      "Naive Bayes               0.051195  \n",
      "K-Nearest Neighbors       0.008146  \n",
      "Random Forest             0.006487  \n",
      "XGBoost                   0.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Fit each classifier and compute evaluation metrics\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f2 = fbeta_score(y_train, y_train_pred, beta=2)\n",
    "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "    results[clf_name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Train Precision': train_precision,\n",
    "        'Test Precision': test_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Test Recall': test_recall,\n",
    "        'Train F1-Score': train_f1,\n",
    "        'Test F1-Score': test_f1,\n",
    "        'Train F2-Score': train_f2,\n",
    "        'Test F2-Score': test_f2\n",
    "    }\n",
    "\n",
    "# Create a table for evaluation metrics\n",
    "metrics_table = pd.DataFrame(results).T\n",
    "\n",
    "print(\"Evaluation Metrics (Training and Test Data):\")\n",
    "print(metrics_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcUDFVr0F5Ex"
   },
   "source": [
    "### 2. Balancing with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_R8E3EYGADJ",
    "outputId": "b34c3241-1820-4ce3-ed8c-0c96bc442b49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (Training and Test Data):\n",
      "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
      "Logistic Regression        0.585504       0.572574         0.582176   \n",
      "Naive Bayes                0.536269       0.401485         0.527603   \n",
      "K-Nearest Neighbors        0.894294       0.709788         0.838445   \n",
      "Random Forest              0.999989       0.898114         0.999977   \n",
      "XGBoost                    0.962706       0.932844         0.998160   \n",
      "\n",
      "                     Test Precision  Train Recall  Test Recall  \\\n",
      "Logistic Regression        0.081974      0.605752     0.551587   \n",
      "Naive Bayes                0.069601      0.693239     0.669312   \n",
      "K-Nearest Neighbors        0.080824      0.976801     0.337302   \n",
      "Random Forest              0.103261      1.000000     0.075397   \n",
      "XGBoost                    0.121951      0.927121     0.006614   \n",
      "\n",
      "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
      "Logistic Regression        0.593730       0.142735        0.600885   \n",
      "Naive Bayes                0.599185       0.126090        0.652283   \n",
      "K-Nearest Neighbors        0.902350       0.130401        0.945594   \n",
      "Random Forest              0.999989       0.087156        0.999995   \n",
      "XGBoost                    0.961330       0.012547        0.940508   \n",
      "\n",
      "                     Test F2-Score  \n",
      "Logistic Regression       0.257058  \n",
      "Naive Bayes               0.245774  \n",
      "K-Nearest Neighbors       0.206344  \n",
      "Random Forest             0.079698  \n",
      "XGBoost                   0.008157  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Fit each classifier and compute evaluation metrics\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_train_pred = clf.predict(X_train_resampled)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "    results[clf_name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Train Precision': train_precision,\n",
    "        'Test Precision': test_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Test Recall': test_recall,\n",
    "        'Train F1-Score': train_f1,\n",
    "        'Test F1-Score': test_f1,\n",
    "        'Train F2-Score': train_f2,\n",
    "        'Test F2-Score': test_f2\n",
    "    }\n",
    "\n",
    "# Create a table for evaluation metrics\n",
    "metrics_table = pd.DataFrame(results).T\n",
    "\n",
    "print(\"Evaluation Metrics (Training and Test Data):\")\n",
    "print(metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdiH0-1EL5AD"
   },
   "source": [
    "### 2. Balancing with OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNo4o0rsIAcg",
    "outputId": "eb2a555c-1abc-4d01-d9c6-edfcb7615137"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (Training and Test Data):\n",
      "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
      "Logistic Regression        0.578622       0.566857         0.575515   \n",
      "Naive Bayes                0.525945       0.364622         0.518909   \n",
      "K-Nearest Neighbors        0.941056       0.785391         0.894545   \n",
      "Random Forest              0.999989       0.920300         0.999977   \n",
      "XGBoost                    0.810613       0.696134         0.770823   \n",
      "\n",
      "                     Test Precision  Train Recall  Test Recall  \\\n",
      "Logistic Regression        0.082689      0.599189     0.566138   \n",
      "Naive Bayes                0.068943      0.711994     0.707672   \n",
      "K-Nearest Neighbors        0.080591      1.000000     0.223545   \n",
      "Random Forest              0.087963      1.000000     0.025132   \n",
      "XGBoost                    0.100086      0.884073     0.464286   \n",
      "\n",
      "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
      "Logistic Regression        0.587114       0.144302        0.594300   \n",
      "Naive Bayes                0.600307       0.125646        0.662678   \n",
      "K-Nearest Neighbors        0.944337       0.118472        0.976966   \n",
      "Random Forest              0.999989       0.039095        0.999995   \n",
      "XGBoost                    0.823573       0.164673        0.858837   \n",
      "\n",
      "                     Test F2-Score  \n",
      "Logistic Regression       0.260976  \n",
      "Naive Bayes               0.248053  \n",
      "K-Nearest Neighbors       0.165007  \n",
      "Random Forest             0.029321  \n",
      "XGBoost                   0.268718  \n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Apply Random Oversampling to balance the training set\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Fit each classifier and compute evaluation metrics\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_train_pred = clf.predict(X_train_resampled)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "    results[clf_name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Train Precision': train_precision,\n",
    "        'Test Precision': test_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Test Recall': test_recall,\n",
    "        'Train F1-Score': train_f1,\n",
    "        'Test F1-Score': test_f1,\n",
    "        'Train F2-Score': train_f2,\n",
    "        'Test F2-Score': test_f2\n",
    "    }\n",
    "\n",
    "# Create a table for evaluation metrics\n",
    "metrics_table = pd.DataFrame(results).T\n",
    "\n",
    "print(\"Evaluation Metrics (Training and Test Data):\")\n",
    "print(metrics_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seUWp7SAMIPb"
   },
   "source": [
    "### 3.Balancing With UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWD3o6rpMN0C",
    "outputId": "c3fec947-2fc5-44f4-b7b0-ec4a8b012824"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aravinda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (Training and Test Data with Random Undersampling):\n",
      "                     Train Accuracy  Test Accuracy  Train Precision  \\\n",
      "Logistic Regression        0.577874       0.556105         0.574441   \n",
      "Naive Bayes                0.535261       0.420599         0.528599   \n",
      "K-Nearest Neighbors        0.709726       0.531018         0.704198   \n",
      "Random Forest              1.000000       0.578462         1.000000   \n",
      "XGBoost                    0.858122       0.556873         0.842004   \n",
      "\n",
      "                     Test Precision  Train Recall  Test Recall  \\\n",
      "Logistic Regression        0.081040      0.600936     0.568783   \n",
      "Naive Bayes                0.070839      0.651738     0.658730   \n",
      "K-Nearest Neighbors        0.074201      0.723262     0.546296   \n",
      "Random Forest              0.086070      1.000000     0.575397   \n",
      "XGBoost                    0.083849      0.881684     0.591270   \n",
      "\n",
      "                     Train F1-Score  Test F1-Score  Train F2-Score  \\\n",
      "Logistic Regression        0.587390       0.141867        0.595443   \n",
      "Naive Bayes                0.583745       0.127922        0.622725   \n",
      "K-Nearest Neighbors        0.713603       0.130655        0.719367   \n",
      "Random Forest              1.000000       0.149742        1.000000   \n",
      "XGBoost                    0.861388       0.146870        0.873452   \n",
      "\n",
      "                     Test F2-Score  \n",
      "Logistic Regression       0.258103  \n",
      "Naive Bayes               0.247663  \n",
      "K-Nearest Neighbors       0.240396  \n",
      "Random Forest             0.269250  \n",
      "XGBoost                   0.267504  \n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply Random Undersampling to the training set\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Fit each classifier and compute evaluation metrics\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_train_pred = clf.predict(X_train_resampled)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_precision = precision_score(y_train_resampled, y_train_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train_resampled, y_train_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f1 = f1_score(y_train_resampled, y_train_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    train_f2 = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "    results[clf_name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy,\n",
    "        'Train Precision': train_precision,\n",
    "        'Test Precision': test_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Test Recall': test_recall,\n",
    "        'Train F1-Score': train_f1,\n",
    "        'Test F1-Score': test_f1,\n",
    "        'Train F2-Score': train_f2,\n",
    "        'Test F2-Score': test_f2\n",
    "    }\n",
    "\n",
    "# Create a table for evaluation metrics\n",
    "metrics_table = pd.DataFrame(results).T\n",
    "\n",
    "print(\"Evaluation Metrics (Training and Test Data with Random Undersampling):\")\n",
    "print(metrics_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqYf5I9vNoQF"
   },
   "source": [
    "*  Now we selected Random forest with SMOTE balancing has some higher performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFhxu0WcO8ih"
   },
   "source": [
    "### Cost sensitive learning to improve F1 score - weighted response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG3NIWarO7TF",
    "outputId": "66b8c179-c184-43b6-92da-db99dda86d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "     Metric  Train      Test\n",
      "0  Accuracy    1.0  0.909293\n",
      "1  F1-Score    1.0  0.068361\n",
      "2  F2-Score    1.0  0.057202\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a Random Forest classifier with class weights\n",
    "class_weights = {0: 1, 1: 1000}  # You can adjust the weight for each class as needed\n",
    "rf_classifier = RandomForestClassifier(random_state=42, class_weight=class_weights)\n",
    "\n",
    "# Fit the model to your resampled training data\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = rf_classifier.predict(X_train_resampled)\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, F1, and F2 scores for both train and test sets\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'F1-Score', 'F2-Score'],\n",
    "    'Train': [accuracy_train, f1_train, f2_train],\n",
    "    'Test': [accuracy_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results:\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQN_am4DOfJL"
   },
   "source": [
    "### Fit SVM -  Balanced dataset(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhBsINklPurg"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Fit the SVM model to the resampled training data\n",
    "svm_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = svm_classifier.predict(X_train_resampled)\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
    "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
    "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results:\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAMhpdcbQ_dZ"
   },
   "source": [
    "### Fit  models with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "paZjeEpcRGat",
    "outputId": "be3e10cd-996e-4653-ffdd-6c7297911731"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define hyperparameters for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "    #'class_weight': [{0: 1, 1: 10}, {0: 1, 1: 15}]  # You can adjust class weights as needed\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator from the hyperparameter tuning\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = best_rf_classifier.predict(X_train_resampled)\n",
    "y_test_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
    "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
    "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results:\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get feature Importance from Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Features:\n",
      "                          Feature  Importance\n",
      "36                  policy_tenure    0.398709\n",
      "38            age_of_policyholder    0.249942\n",
      "37                     age_of_car    0.184341\n",
      "0              population_density    0.139641\n",
      "4                    gross_weight    0.002379\n",
      "2                          length    0.002337\n",
      "3                          height    0.002214\n",
      "44          no_of_safety_measures    0.002069\n",
      "1                           width    0.002059\n",
      "42                 turning_radius    0.002023\n",
      "28  engine_type_F8D Petrol Engine    0.001535\n",
      "43                    ncap_rating    0.001343\n",
      "35                     is_ecw_Yes    0.001103\n",
      "41                     cylinder.1    0.000944\n",
      "40                       cylinder    0.000786\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a Random Forest classifier with tuned hyperparameters\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,  # Your chosen value\n",
    "    max_depth=None,    # Your chosen value\n",
    "    min_samples_split=5,  # Your chosen value\n",
    "    min_samples_leaf=10,   # Your chosen value\n",
    "    #class_weight={0: 1, 1: 100},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to your resampled training data\n",
    "#rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top 15 features and their importances as a table\n",
    "top_15_features = feature_importance_df.head(15)\n",
    "print(\"Top 15 Features:\")\n",
    "print(top_15_features)\n",
    "\n",
    "# Create a bar graph to visualize the top 15 features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(top_15_features['Feature'], top_15_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis to display the most important feature at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model again with 5 important  features (By RF feature Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random forest (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Top 5 Features:\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.970648   0.908866\n",
      "1  Precision       0.989686   0.093750\n",
      "2     Recall       0.951209   0.047619\n",
      "3   F1-Score       0.970066   0.063158\n",
      "4   F2-Score       0.958663   0.052817\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 5 features\n",
    "top_5_features = feature_importance_df.head(5)\n",
    "\n",
    "# Create new DataFrames with only the top 5 features\n",
    "X_train_top5 = X_train_resampled[top_5_features['Feature']]\n",
    "X_test_top5 = X_test[top_5_features['Feature']]\n",
    "\n",
    "# Create a new Random Forest classifier with the top 5 features\n",
    "rf_classifier_top5 = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None , \n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data with the top 5 features\n",
    "rf_classifier_top5.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred_top5 = rf_classifier_top5.predict(X_train_top5)\n",
    "y_test_pred_top5 = rf_classifier_top5.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data with top 5 features\n",
    "accuracy_train_top5 = accuracy_score(y_train_resampled, y_train_pred_top5)\n",
    "precision_train_top5 = precision_score(y_train_resampled, y_train_pred_top5)\n",
    "recall_train_top5 = recall_score(y_train_resampled, y_train_pred_top5)\n",
    "f1_train_top5 = f1_score(y_train_resampled, y_train_pred_top5)\n",
    "f2_train_top5 = fbeta_score(y_train_resampled, y_train_pred_top5, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data with top 5 features\n",
    "accuracy_test_top5 = accuracy_score(y_test, y_test_pred_top5)\n",
    "precision_test_top5 = precision_score(y_test, y_test_pred_top5)\n",
    "recall_test_top5 = recall_score(y_test, y_test_pred_top5)\n",
    "f1_test_top5 = f1_score(y_test, y_test_pred_top5)\n",
    "f2_test_top5 = fbeta_score(y_test, y_test_pred_top5, beta=2)\n",
    "\n",
    "# Create a table for the results with top 5 features\n",
    "results_table_top5 = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train_top5, precision_train_top5, recall_train_top5, f1_train_top5, f2_train_top5],\n",
    "    'Test Data': [accuracy_test_top5, precision_test_top5, recall_test_top5, f1_test_top5, f2_test_top5]\n",
    "})\n",
    "\n",
    "print(\"Results with Top 5 Features:\")\n",
    "print(results_table_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic(Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Lasso Logistic Regression and Top 5 Features:\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.581265   0.567113\n",
      "1  Precision       0.577779   0.081605\n",
      "2     Recall       0.603678   0.556878\n",
      "3   F1-Score       0.590445   0.142350\n",
      "4   F2-Score       0.598314   0.257241\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 5 features\n",
    "top_5_features = feature_importance_df.head(5)\n",
    "\n",
    "# Create new DataFrames with only the top 5 features\n",
    "X_train_top5 = X_train_resampled[top_5_features['Feature']]\n",
    "X_test_top5 = X_test[top_5_features['Feature']]\n",
    "\n",
    "\n",
    "# Create a Lasso Logistic Regression classifier\n",
    "lasso_logistic = LogisticRegression(penalty='l2', solver='liblinear', random_state=42)\n",
    "\n",
    "# Fit the model to the training data with the top 5 features\n",
    "lasso_logistic.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = lasso_logistic.predict(X_train_top5)\n",
    "y_test_pred = lasso_logistic.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
    "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
    "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results with Lasso Logistic Regression and Top 5 Features:\")\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Gaussian Naive Bayes and Top 5 Features:\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.589834   0.528629\n",
      "1  Precision       0.578557   0.080134\n",
      "2     Recall       0.661608   0.601852\n",
      "3   F1-Score       0.617302   0.141436\n",
      "4   F2-Score       0.643143   0.261434\n"
     ]
    }
   ],
   "source": [
    "# Create a Gaussian Naive Bayes classifier\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Fit the model to the training data with the top 5 features\n",
    "naive_bayes_classifier.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = naive_bayes_classifier.predict(X_train_top5)\n",
    "y_test_pred = naive_bayes_classifier.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
    "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
    "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results with Gaussian Naive Bayes and Top 5 Features:\")\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Xgboost model (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Tuned XGBoost and Top 5 Features:\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.964130   0.934209\n",
      "1  Precision       0.999387   0.105263\n",
      "2     Recall       0.928830   0.002646\n",
      "3   F1-Score       0.962818   0.005161\n",
      "4   F2-Score       0.942133   0.003286\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define a parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search CV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(xgb_classifier, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the training data with the top 5 features\n",
    "best_xgb_classifier.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data\n",
    "y_train_pred = best_xgb_classifier.predict(X_train_top5)\n",
    "y_test_pred = best_xgb_classifier.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision_train = precision_score(y_train_resampled, y_train_pred)\n",
    "recall_train = recall_score(y_train_resampled, y_train_pred)\n",
    "f1_train = f1_score(y_train_resampled, y_train_pred)\n",
    "f2_train = fbeta_score(y_train_resampled, y_train_pred, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "f2_test = fbeta_score(y_test, y_test_pred, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train, precision_train, recall_train, f1_train, f2_train],\n",
    "    'Test Data': [accuracy_test, precision_test, recall_test, f1_test, f2_test]\n",
    "})\n",
    "\n",
    "print(\"Results with Tuned XGBoost and Top 5 Features:\")\n",
    "print(results_table)\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=42, ...)\n"
     ]
    }
   ],
   "source": [
    "print(best_xgb_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble modeling (XGB, Logistic, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Ensemble Model (Hard Voting):\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.890864   0.920130\n",
      "1  Precision       0.979588   0.137097\n",
      "2     Recall       0.798364   0.044974\n",
      "3   F1-Score       0.879740   0.067729\n",
      "4   F2-Score       0.829038   0.051956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "# Define tuned parameters for each classifier\n",
    "rf_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'class_weight': 'balanced',\n",
    "    #'class_weight': {0: 1, 1: 20},\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    #'scale_pos_weight': 20,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "# Create classifiers with tuned parameters\n",
    "rf_classifier = RandomForestClassifier(**rf_params)\n",
    "xgb_classifier = XGBClassifier(**xgb_params)\n",
    "#logistic_classifier = LogisticRegression(**logistic_params)\n",
    "\n",
    "# Create an ensemble model using hard voting\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('xgb', xgb_classifier),\n",
    "        #('logistic', logistic_classifier)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Fit the ensemble model to the training data with the top 5 features\n",
    "ensemble_classifier.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data with the ensemble model\n",
    "y_train_pred_ensemble = ensemble_classifier.predict(X_train_top5)\n",
    "y_test_pred_ensemble = ensemble_classifier.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train_ensemble = accuracy_score(y_train_resampled, y_train_pred_ensemble)\n",
    "precision_train_ensemble = precision_score(y_train_resampled, y_train_pred_ensemble)\n",
    "recall_train_ensemble = recall_score(y_train_resampled, y_train_pred_ensemble)\n",
    "f1_train_ensemble = f1_score(y_train_resampled, y_train_pred_ensemble)\n",
    "f2_train_ensemble = fbeta_score(y_train_resampled, y_train_pred_ensemble, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test_ensemble = accuracy_score(y_test, y_test_pred_ensemble)\n",
    "precision_test_ensemble = precision_score(y_test, y_test_pred_ensemble)\n",
    "recall_test_ensemble = recall_score(y_test, y_test_pred_ensemble)\n",
    "f1_test_ensemble = f1_score(y_test, y_test_pred_ensemble)\n",
    "f2_test_ensemble = fbeta_score(y_test, y_test_pred_ensemble, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train_ensemble, precision_train_ensemble, recall_train_ensemble, f1_train_ensemble, f2_train_ensemble],\n",
    "    'Test Data': [accuracy_test_ensemble, precision_test_ensemble, recall_test_ensemble, f1_test_ensemble, f2_test_ensemble]\n",
    "})\n",
    "\n",
    "print(\"Results with Ensemble Model (Hard Voting):\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Ensemble Model (soft Voting):\n",
      "      Metric  Training Data  Test Data\n",
      "0   Accuracy       0.930938   0.912706\n",
      "1  Precision       0.970749   0.140162\n",
      "2     Recall       0.888653   0.068783\n",
      "3   F1-Score       0.927889   0.092280\n",
      "4   F2-Score       0.903943   0.076583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "# Define tuned parameters for each classifier\n",
    "rf_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'class_weight': 'balanced',\n",
    "    #'class_weight': {0: 1, 1: 20},\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.8,\n",
    "    #'scale_pos_weight': 20,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "\n",
    "# Create classifiers with tuned parameters\n",
    "rf_classifier = RandomForestClassifier(**rf_params)\n",
    "xgb_classifier = XGBClassifier(**xgb_params)\n",
    "#logistic_classifier = LogisticRegression(**logistic_params)\n",
    "\n",
    "# Create an ensemble model using hard voting\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_classifier),\n",
    "        ('xgb', xgb_classifier),\n",
    "        #('logistic', logistic_classifier)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Fit the ensemble model to the training data with the top 5 features\n",
    "ensemble_classifier.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Make predictions on both train and test data with the ensemble model\n",
    "y_train_pred_ensemble = ensemble_classifier.predict(X_train_top5)\n",
    "y_test_pred_ensemble = ensemble_classifier.predict(X_test_top5)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for training data\n",
    "accuracy_train_ensemble = accuracy_score(y_train_resampled, y_train_pred_ensemble)\n",
    "precision_train_ensemble = precision_score(y_train_resampled, y_train_pred_ensemble)\n",
    "recall_train_ensemble = recall_score(y_train_resampled, y_train_pred_ensemble)\n",
    "f1_train_ensemble = f1_score(y_train_resampled, y_train_pred_ensemble)\n",
    "f2_train_ensemble = fbeta_score(y_train_resampled, y_train_pred_ensemble, beta=2)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1, and F2 scores for test data\n",
    "accuracy_test_ensemble = accuracy_score(y_test, y_test_pred_ensemble)\n",
    "precision_test_ensemble = precision_score(y_test, y_test_pred_ensemble)\n",
    "recall_test_ensemble = recall_score(y_test, y_test_pred_ensemble)\n",
    "f1_test_ensemble = f1_score(y_test, y_test_pred_ensemble)\n",
    "f2_test_ensemble = fbeta_score(y_test, y_test_pred_ensemble, beta=2)\n",
    "\n",
    "# Create a table for the results\n",
    "results_table = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'F2-Score'],\n",
    "    'Training Data': [accuracy_train_ensemble, precision_train_ensemble, recall_train_ensemble, f1_train_ensemble, f2_train_ensemble],\n",
    "    'Test Data': [accuracy_test_ensemble, precision_test_ensemble, recall_test_ensemble, f1_test_ensemble, f2_test_ensemble]\n",
    "})\n",
    "\n",
    "print(\"Results with Ensemble Model (soft Voting):\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDP for random forest model with only five variable mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pdpbox.pdp' has no attribute 'pdp_isolate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_feature_name_here\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate the PDP for the chosen feature\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pdp_feature \u001b[38;5;241m=\u001b[39m \u001b[43mpdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdp_isolate\u001b[49m(model\u001b[38;5;241m=\u001b[39mrf_classifier, dataset\u001b[38;5;241m=\u001b[39mX_test_top5, model_features\u001b[38;5;241m=\u001b[39mX_test_top5\u001b[38;5;241m.\u001b[39mcolumns, feature\u001b[38;5;241m=\u001b[39mfeature_name)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create the PDP plot\u001b[39;00m\n\u001b[0;32m     22\u001b[0m pdp\u001b[38;5;241m.\u001b[39mpdp_plot(pdp_feature, feature_name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pdpbox.pdp' has no attribute 'pdp_isolate'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pdpbox import pdp, info_plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your original dataset\n",
    "# Assuming you have a DataFrame named 'data' with features and labels (X and y)\n",
    "\n",
    "# Fit a Random Forest model (you can use your tuned model)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "rf_classifier.fit(X_train_top5, y_train_resampled)\n",
    "\n",
    "# Choose the feature for which you want to create the PDP\n",
    "# Replace 'feature_name' with the actual name of the feature you want to plot\n",
    "feature_name = 'your_feature_name_here'\n",
    "\n",
    "# Calculate the PDP for the chosen feature\n",
    "pdp_feature = pdp.pdp_isolate(model=rf_classifier, dataset=X_test_top5, model_features=X_test_top5.columns, feature=feature_name)\n",
    "\n",
    "# Create the PDP plot\n",
    "pdp.pdp_plot(pdp_feature, feature_name)\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel(\"Partial Dependence\")\n",
    "plt.title(f'Partial Dependence Plot for {feature_name}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import (partial_dependence, \n",
    "                                PartialDependenceDisplay)\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.ensemble.partial_dependence'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartial_dependence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial_dependence, plot_partial_dependence\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# scikit-learn originally implemented partial dependence plots only for Gradient Boosting models\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# this was due to an implementation detail, and a future release will support all model types.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#my_model = GradientBoostingRegressor()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# fit the model as usual\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#my_model.fit(X, y)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Here we make the plot\u001b[39;00m\n\u001b[0;32m      8\u001b[0m my_plots \u001b[38;5;241m=\u001b[39m plot_partial_dependence(rf_classifier_top5,       \n\u001b[0;32m      9\u001b[0m                                    features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m], \u001b[38;5;66;03m# column numbers of plots we want to show\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                                    X\u001b[38;5;241m=\u001b[39mX_train_top5,            \u001b[38;5;66;03m# raw predictors data.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m                                    feature_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolicy_tenure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_of_policyholder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_of_car\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopulation_density\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# labels on graphs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m                                    grid_resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.ensemble.partial_dependence'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "# scikit-learn originally implemented partial dependence plots only for Gradient Boosting models\n",
    "# this was due to an implementation detail, and a future release will support all model types.\n",
    "#my_model = GradientBoostingRegressor()\n",
    "# fit the model as usual\n",
    "#my_model.fit(X, y)\n",
    "# Here we make the plot\n",
    "my_plots = plot_partial_dependence(rf_classifier_top5,       \n",
    "                                   features=[0,1,2,3,4], # column numbers of plots we want to show\n",
    "                                   X=X_train_top5,            # raw predictors data.\n",
    "                                   feature_names=['policy_tenure', 'age_of_policyholder', 'age_of_car','population_density'], # labels on graphs\n",
    "                                   grid_resolution=10) # number of values to plot on x axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Feature  Importance\n",
    "36                  policy_tenure    0.398709\n",
    "38            age_of_policyholder    0.249942\n",
    "37                     age_of_car    0.184341\n",
    "0              population_density    0.139641\n",
    "4                    gross_weight    0.002379\n",
    "2                          length    0.002337\n",
    "3                          height    0.002214\n",
    "44          no_of_safety_measures    0.002069\n",
    "1                           width    0.002059\n",
    "42                 turning_radius    0.002023\n",
    "28  engine_type_F8D Petrol Engine    0.001535\n",
    "43                    ncap_rating    0.001343\n",
    "35                     is_ecw_Yes    0.001103\n",
    "41                     cylinder.1    0.000944\n",
    "40                       cylinder    0.000786"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
